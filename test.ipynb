{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6515d167",
   "metadata": {},
   "source": [
    "Here's a step-by-step guide to building your ASL recognition model using Jupyter Notebooks, covering every stage from data preparation to model deployment:\n",
    "\n",
    "### 1. Setup Notebook Environment\n",
    "Create `1_Environment_Setup.ipynb`:\n",
    "```python\n",
    "# Cell 1: Verify GPU\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "# Cell 2: Install packages (run once)\n",
    "!pip install numpy==1.19.5 tensorflow-gpu==2.6.0 opencv-python matplotlib pillow\n",
    "\n",
    "# Cell 3: Verify packages\n",
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "```\n",
    "\n",
    "### 2. Data Exploration & Preparation\n",
    "Create `2_Data_Preparation.ipynb`:\n",
    "```python\n",
    "# Cell 1: Load dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataset_path = \"dataset/asl_alphabet_train\"\n",
    "class_names = sorted(os.listdir(dataset_path))\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Cell 2: Visualize samples\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, class_name in enumerate(class_names[:5]):\n",
    "    img_path = os.path.join(dataset_path, class_name, os.listdir(os.path.join(dataset_path, class_name))[0])\n",
    "    img = plt.imread(img_path)\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(class_name)\n",
    "plt.show()\n",
    "\n",
    "# Cell 3: Create generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. Model Building\n",
    "Create `3_Model_Building.ipynb`:\n",
    "```python\n",
    "# Cell 1: Define model architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(29, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Cell 2: Train model\n",
    "EPOCHS = 15\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# Cell 3: Save model\n",
    "model.save('asl_model.h5')\n",
    "```\n",
    "\n",
    "### 4. Model Evaluation\n",
    "Create `4_Model_Evaluation.ipynb`:\n",
    "```python\n",
    "# Cell 1: Load model\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('asl_model.h5')\n",
    "\n",
    "# Cell 2: Plot training history\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Cell 3: Test prediction\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    img = img/255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    pred = model.predict(img)\n",
    "    class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    plt.imshow(img[0])\n",
    "    plt.title(f\"Predicted: {class_names[class_idx]}\\nConfidence: {confidence:.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Test with sample image\n",
    "predict_image(\"dataset/asl_alphabet_test/A_test.jpg\")\n",
    "```\n",
    "\n",
    "### 5. Flask API Development\n",
    "Create `5_API_Development.ipynb`:\n",
    "```python\n",
    "# Cell 1: Create Flask app template\n",
    "%%writefile app.py\n",
    "from flask import Flask, request, jsonify\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = load_model('asl_model.h5')\n",
    "class_names = ['A', 'B', 'C', ..., 'space']  # Complete with all 29 classes\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file uploaded'}), 400\n",
    "    \n",
    "    file = request.files['file']\n",
    "    img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    img = img/255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    pred = model.predict(img)\n",
    "    return jsonify({\n",
    "        'prediction': class_names[np.argmax(pred)],\n",
    "        'confidence': float(np.max(pred))\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "# Cell 2: Test API locally\n",
    "!python app.py\n",
    "```\n",
    "\n",
    "### 6. Deployment Preparation\n",
    "Create `6_Deployment_Preparation.ipynb`:\n",
    "```python\n",
    "# Cell 1: Create requirements.txt\n",
    "%%writefile requirements.txt\n",
    "numpy==1.19.5\n",
    "tensorflow-gpu==2.6.0\n",
    "opencv-python-headless==4.5.5.64\n",
    "Flask==2.0.3\n",
    "Pillow==9.0.1\n",
    "protobuf==3.20.3\n",
    "\n",
    "# Cell 2: Create vercel.json\n",
    "%%writefile vercel.json\n",
    "{\n",
    "  \"version\": 2,\n",
    "  \"builds\": [\n",
    "    {\n",
    "      \"src\": \"app.py\",\n",
    "      \"use\": \"@vercel/python\"\n",
    "    }\n",
    "  ],\n",
    "  \"routes\": [\n",
    "    {\n",
    "      \"src\": \"/(.*)\",\n",
    "      \"dest\": \"app.py\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Cell 3: Test deployment package\n",
    "!pip install -r requirements.txt\n",
    "!python app.py\n",
    "```\n",
    "\n",
    "### Workflow Recommendation:\n",
    "1. Execute notebooks in order (1 â†’ 6)\n",
    "2. For training, use GPU runtime in Colab or local machine\n",
    "3. For deployment, upload the entire project to GitHub and connect to Vercel\n",
    "4. Monitor training with TensorBoard if needed:\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n",
    "```\n",
    "\n",
    "Each notebook corresponds to a clear stage in your project lifecycle, making it easy to debug and modify specific components. The notebooks include both code and markdown cells where you can add explanations and observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492bd31",
   "metadata": {},
   "source": [
    "Yes! Let's implement a more complex and powerful model architecture that can deliver better accuracy for ASL recognition. Here's an enhanced version with modern deep learning techniques:\n",
    "\n",
    "### Enhanced ASL Recognition Model Architecture\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_enhanced_model(input_shape=(64, 64, 3), num_classes=29):\n",
    "    model = Sequential([\n",
    "        # Block 1\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu', \n",
    "               kernel_regularizer=l2(0.001), input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Block 2\n",
    "        Conv2D(128, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Block 3\n",
    "        Conv2D(256, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Block 4\n",
    "        Conv2D(512, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(512, (3,3), padding='same', activation='relu',\n",
    "               kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Classifier\n",
    "        Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Custom optimizer configuration\n",
    "    optimizer = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "enhanced_model = create_enhanced_model()\n",
    "enhanced_model.summary()\n",
    "```\n",
    "\n",
    "### Key Improvements:\n",
    "\n",
    "1. **Deeper Architecture**:\n",
    "   - 4 convolutional blocks (vs original 3)\n",
    "   - More filters per layer (up to 512)\n",
    "   - Added residual-like connections through batch normalization\n",
    "\n",
    "2. **Advanced Techniques**:\n",
    "   - **Batch Normalization**: After each conv layer for stable training\n",
    "   - **L2 Regularization**: Penalizes large weights to prevent overfitting\n",
    "   - **Global Average Pooling**: Redplaces Flatten() for better spatial awareness\n",
    "   - **Custom Adam Optimizer**: Fine-tuned learning rate\n",
    "\n",
    "3. **Enhanced Classifier**:\n",
    "   - Two dense layers (1024 and 512 units)\n",
    "   - Strategic dropout placement (30% in conv blocks, 50% in dense layers)\n",
    "\n",
    "4. **Input Flexibility**:\n",
    "   - Configurable input shape and number of classes\n",
    "\n",
    "### Training Recommendations:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7),\n",
    "    ModelCheckpoint('best_enhanced_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = enhanced_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "```\n",
    "\n",
    "### Potential Further Enhancements:\n",
    "\n",
    "1. **Transfer Learning**:\n",
    "```python\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(64,64,3)\n",
    ")\n",
    "base_model.trainable = False  # Freeze layers\n",
    "```\n",
    "\n",
    "2. **Attention Mechanisms**:\n",
    "```python\n",
    "from tensorflow.keras.layers import Multiply, GlobalMaxPooling2D\n",
    "\n",
    "# Squeeze-and-Excitation style attention\n",
    "def channel_attention(input_tensor):\n",
    "    channels = input_tensor.shape[-1]\n",
    "    gap = GlobalAveragePooling2D()(input_tensor)\n",
    "    dense = Dense(channels//8, activation='relu')(gap)\n",
    "    attention = Dense(channels, activation='sigmoid')(dense)\n",
    "    return Multiply()([input_tensor, attention])\n",
    "```\n",
    "\n",
    "3. **Data Augmentation**:\n",
    "```python\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.7,1.3],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect'  # Better for hand images\n",
    ")\n",
    "```\n",
    "\n",
    "This enhanced model should provide significantly better accuracy while maintaining reasonable training times. The added complexity is justified by:\n",
    "\n",
    "1. Better feature extraction through deeper conv blocks\n",
    "2. More stable training via batch normalization\n",
    "3. Reduced overfitting through multiple regularization techniques\n",
    "4. Finer gradient control with custom optimizer settings\n",
    "\n",
    "Would you like me to focus on any specific aspect of this enhanced architecture, or would you prefer to see a different approach (like transfer learning with pretrained models)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c699d0f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
